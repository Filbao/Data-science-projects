{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOLUP3t1IZalWwIEIlBscDH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["***Web scraping***"],"metadata":{"id":"MfQ21cWQ7wLw"}},{"cell_type":"code","source":["#Utilize Python libraries such as BeautifulSoup to scrape product information from an online website.\n","#Collect data attributes including product names, categories, prices, availability status, and promotional details.\n","!pip install selenium beautifulsoup4 pandas plotly numpy\n","\n","#Utilize Python libraries such as BeautifulSoup to scrape product information from an online website.\n","#Collect data attributes including product names, categories, prices, availability status, and promotional details.\n","import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import re\n","from datetime import datetime\n","import numpy as np\n","import warnings\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","import time\n","warnings.filterwarnings('ignore')\n","\n","# Web Scraping with Selenium and BeautifulSoup\n","def scrape_aziza_products(url):\n","    # Set up Selenium with headless Chrome\n","    chrome_options = Options()\n","    chrome_options.add_argument('--headless')  # Run without opening browser\n","    chrome_options.add_argument('--disable-gpu')\n","    chrome_options.add_argument('--no-sandbox')\n","    chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36')\n","\n","    try:\n","        driver = webdriver.Chrome(options=chrome_options)\n","        driver.get(url)\n","        time.sleep(5)  # Wait for JavaScript to load content\n","\n","        # Parse the rendered page with BeautifulSoup\n","        soup = BeautifulSoup(driver.page_source, 'html.parser')\n","        driver.quit()\n","\n","        products = []\n","        # Hypothetical selectors; update after inspecting the website\n","        product_elements = soup.select('div.product-card, div.item, article.product')  # Common product container classes\n","\n","        for item in product_elements:\n","            try:\n","                name = item.select_one('h2, h3, .product-title, .item-name').text.strip() if item.select_one('h2, h3, .product-title, .item-name') else 'Unknown'\n","                category = item.select_one('.category, .product-category, span.cat').text.strip() if item.select_one('.category, .product-category, span.cat') else 'Uncategorized'\n","                price = item.select_one('.price, .product-price, .amount').text.strip() if item.select_one('.price, .product-price, .amount') else 'N/A'\n","                availability = item.select_one('.stock, .availability, .in-stock').text.strip() if item.select_one('.stock, .availability, .in-stock') else 'Unknown'\n","                promo = item.select_one('.promo, .promotion, .discount').text.strip() if item.select_one('.promo, .promotion, .discount') else 'No Promo'\n","\n","                products.append({\n","                    'name': name,\n","                    'category': category,\n","                    'price': price,\n","                    'availability': availability,\n","                    'promo': promo,\n","                    'scrape_date': datetime.now().strftime('%Y-%m-%d')\n","                })\n","            except AttributeError:\n","                continue\n","\n","        return products\n","    except Exception as e:\n","        print(f\"Error during scraping: {e}\")\n","        return []\n","\n","# Data cleaning\n","def clean_data(df):\n","    # Handle missing prices\n","    df['price'] = df['price'].replace('N/A', np.nan)\n","    df['price'] = df['price'].apply(lambda x: re.sub(r'[^\\d,.]', '', str(x)) if pd.notna(x) else np.nan)\n","    df['price'] = df['price'].str.replace(',', '.').astype(float)\n","\n","    # Standardize text fields\n","    df['name'] = df['name'].str.lower().str.strip()\n","    df['category'] = df['category'].str.lower().str.strip()\n","    df['availability'] = df['availability'].str.lower().str.strip()\n","    df['promo'] = df['promo'].str.lower().str.strip()\n","\n","    # Fill missing categories\n","    df['category'] = df['category'].replace('uncategorized', 'other')\n","\n","    # Remove duplicates\n","    df = df.drop_duplicates(subset=['name', 'category'])\n","\n","    return df\n","\n","# Data transformation\n","def transform_data(df):\n","    # Categorize products into hierarchical groups (simplified example)\n","    category_hierarchy = {\n","        'electronics': ['phone', 'tv', 'refrigerator', 'climatiseur'],\n","        'food': ['oil', 'tuna', 'pasta'],\n","        'cleaning': ['detergent', 'cleaner']\n","    }\n","\n","    def assign_hierarchy(category):\n","        for main_cat, sub_cats in category_hierarchy.items():\n","            if any(sub_cat in category for sub_cat in sub_cats):\n","                return f\"{main_cat} > {category}\"\n","        return f\"other > {category}\"\n","\n","    df['category_hierarchy'] = df['category'].apply(assign_hierarchy)\n","\n","    return df\n","\n","# Data analysis\n","def analyze_data(df):\n","    # Average pricing by category\n","    avg_price = df.groupby('category_hierarchy')['price'].mean().reset_index()\n","\n","    # Promotional patterns\n","    promo_counts = df['promo'].value_counts().reset_index()\n","    promo_counts.columns = ['promo', 'count']\n","\n","    # Availability trends\n","    availability_counts = df['availability'].value_counts().reset_index()\n","    availability_counts.columns = ['availability', 'count']\n","\n","    return avg_price, promo_counts, availability_counts\n","\n","\n","# Data visualisation\n","def visualize_data(avg_price, promo_counts, availability_counts):\n","    # Average Price by Category\n","    fig1 = px.bar(avg_price, x='category_hierarchy', y='price', title='Average Price by Category',\n","                  labels={'price': 'Average Price (TND)', 'category_hierarchy': 'Category'})\n","    fig1.update_layout(xaxis_tickangle=45)\n","    fig1.write('price_by_category.html')\n","\n","    # Promotional Distribution\n","    fig2 = px.pie(promo_counts, values='count', names='promo', title='Promotional Distribution')\n","    fig2.write('promo_distribution.html')\n","\n","    # Availability Status\n","    fig3 = px.bar(availability_counts, x='availability', y='count', title='Product Availability Status',\n","                  labels={'count': 'Number of Products'})\n","    fig3.write('availability_status.html')\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    url = \"https://aziza.tn/\"\n","    products = scrape_aziza_products(url)\n","\n","    if products:\n","        df = pd.DataFrame(products)\n","        df = clean_data(df)\n","        df = transform_data(df)\n","\n","        avg_price, promo_counts, availability_counts = analyze_data(df)\n","        visualize_data(avg_price, promo_counts, availability_counts)\n","\n","        # Save cleaned data\n","        df.to_csv('aziza_products.csv', index=False)\n","        print(\"Data scraping, cleaning, analysis, and visualization completed.\")\n","    else:\n","        print(\"No products scraped. Check website structure or JavaScript requirements.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G836zAqEPili","executionInfo":{"status":"ok","timestamp":1750154023648,"user_tz":-180,"elapsed":30113,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"c2457318-ad17-42ab-a305-b0edcb02fdf7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.33.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: urllib3~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n","Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n","Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n","Requirement already satisfied: certifi>=2025.4.26 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n","Requirement already satisfied: typing_extensions~=4.13.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n","Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n","No products scraped. Check website structure or JavaScript requirements.\n"]}]},{"cell_type":"markdown","source":["***Data cleaning***"],"metadata":{"id":"paHXZL6ZP8aA"}},{"cell_type":"code","source":["#Address missing or inconsistent data entries, such as absent prices or ambiguous product descriptions.\n","#Standardize text fields to ensure uniformity in product names and categories.\n"],"metadata":{"id":"Il3RjaiVP-f5","executionInfo":{"status":"ok","timestamp":1750154072870,"user_tz":-180,"elapsed":22,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["***Data transformation***"],"metadata":{"id":"rfkA_2hfQZCF"}},{"cell_type":"code","source":["#Convert price data into numerical formats for analysis.\n","#Categorize products into hierarchical groups (e.g., Electronics > Mobile Phones > Smartphones).\n","def transform_data(df):\n","    pass"],"metadata":{"id":"Y8cTSFGMQcOd","executionInfo":{"status":"ok","timestamp":1750154198136,"user_tz":-180,"elapsed":5,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["***Data analysis***"],"metadata":{"id":"8_eoHnDkQo2y"}},{"cell_type":"code","source":["#Conduct exploratory data analysis (EDA) to uncover insights:\n","#Identify average pricing within each product category.\n","#Conduct exploratory data analysis (EDA) to uncover insights:\n","#Identify average pricing within each product category.\n","#Detect seasonal or promotional pricing patterns.\n","#Assess product availability trends over time.\n","def analyze_data(df):\n","    pass"],"metadata":{"id":"rhzW2t2aQq9F","executionInfo":{"status":"ok","timestamp":1750154221381,"user_tz":-180,"elapsed":5,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["***Data visualisation***"],"metadata":{"id":"rAGN3auPRHOq"}},{"cell_type":"code","source":["#Employ visualization library Plotly to create some charts.\n"],"metadata":{"id":"cI-gpy9iRJoW","executionInfo":{"status":"ok","timestamp":1750153374999,"user_tz":-180,"elapsed":65,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":23,"outputs":[]}]}