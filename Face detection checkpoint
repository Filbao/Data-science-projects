{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwEs1wkNxUq66TpqSA81m5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Improving the Streamlit app for face detection using Viola-Jones algorithm of the example of the content\n","\n","\n","Instructions\n","Add instructions to the Streamlit app interface to guide the user on how to use the app.\n","Add a feature to save the images with detected faces on the user's device.\n","Add a feature to allow the user to choose the color of the rectangles drawn around the detected faces.\n","Add a feature to adjust the minNeighbors parameter in the face_cascade.detectMultiScale() function.\n","Add a feature to adjust the scaleFactor parameter in the face_cascade.detectMultiScale() function.\n","Hints:\n","\n","Use the st.write() or st.markdown() functions to add instructions to the interface.\n","\n","Use the cv2.imwrite() function to save the images.\n","Use the st.color_picker() function to allow the user to choose the color of the rectangles.\n","Use the st.slider() function to allow the user to adjust the minNeighbors parameter.\n","Use the st.slider() function to allow the user to adjust the scaleFactor parameter."],"metadata":{"id":"dt4kzGX7URrC"}},{"cell_type":"code","source":["!pip install streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8uabGE1Uxsk","executionInfo":{"status":"ok","timestamp":1755255385283,"user_tz":-180,"elapsed":4862,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"1f4e482c-f430-4c57-cc29-0f6c617368fd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.1)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXJygr2_UEx9","executionInfo":{"status":"ok","timestamp":1755255385312,"user_tz":-180,"elapsed":35,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"d733f045-dba7-4b26-bc81-68cadc7b3fee"},"outputs":[{"output_type":"stream","name":"stderr","text":["2025-08-15 10:56:24.714 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.714 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.718 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.724 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.729 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.730 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.731 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.731 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.735 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-15 10:56:24.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"]}],"source":["import streamlit as st\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import os\n","\n","def detect_faces(image, scale_factor, min_neighbors):\n","    \"\"\"Detect faces in the image using Viola-Jones algorithm.\"\"\"\n","    # Convert PIL image to OpenCV format\n","    img_array = np.array(image)\n","    if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n","        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n","    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n","\n","    # Load Haar cascade\n","    cascade_path = \"haarcascade_frontalface_default.xml\"\n","    if not os.path.exists(cascade_path):\n","        st.error(\"Error: Haar cascade file 'haarcascade_frontalface_default.xml' not found.\")\n","        return None, []\n","\n","    face_cascade = cv2.CascadeClassifier(cascade_path)\n","    if face_cascade.empty():\n","        st.error(\"Error: Failed to load Haar cascade classifier.\")\n","        return None, []\n","\n","    # Detect faces\n","    faces = face_cascade.detectMultiScale(\n","        gray,\n","        scaleFactor=scale_factor,\n","        minNeighbors=min_neighbors,\n","        minSize=(30, 30)\n","    )\n","\n","    return img_array, faces\n","\n","def draw_faces(image, faces, color_hex):\n","    \"\"\"Draw rectangles around detected faces with the chosen color.\"\"\"\n","    if image is None:\n","        return None\n","\n","    # Convert hex color to BGR\n","    color_rgb = tuple(int(color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n","    color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])  # Reverse to BGR\n","\n","    img_copy = image.copy()\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(img_copy, (x, y), (x + w, y + h), color_bgr, 2)\n","\n","    return img_copy\n","\n","def main():\n","    \"\"\"Streamlit app for face detection.\"\"\"\n","    st.title(\"Face Detection with Viola-Jones Algorithm\")\n","\n","    # Instructions\n","    st.markdown(\"\"\"\n","    **Instructions:**\n","    1. Upload an image (JPG, PNG) containing faces.\n","    2. Adjust the **Scale Factor** and **Min Neighbors** sliders to fine-tune face detection.\n","    3. Choose a color for the face detection rectangles using the color picker.\n","    4. View the image with detected faces.\n","    5. Click the **Save Image** button to download the result.\n","    \"\"\")\n","\n","    # File uploader\n","    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n","\n","    # Parameters\n","    scale_factor = st.slider(\n","        \"Scale Factor (controls detection sensitivity)\",\n","        min_value=1.1,\n","        max_value=2.0,\n","        value=1.3,\n","        step=0.1\n","    )\n","    min_neighbors = st.slider(\n","        \"Min Neighbors (controls detection strictness)\",\n","        min_value=3,\n","        max_value=10,\n","        value=5,\n","        step=1\n","    )\n","    rect_color = st.color_picker(\"Choose rectangle color\", \"#FF0000\")\n","\n","    if uploaded_file is not None:\n","        try:\n","            # Load image\n","            image = Image.open(uploaded_file)\n","            if image.mode != 'RGB':\n","                image = image.convert('RGB')\n","\n","            # Detect faces\n","            img_with_faces, faces = detect_faces(image, scale_factor, min_neighbors)\n","\n","            if img_with_faces is None:\n","                st.error(\"Failed to process image. Please try another image.\")\n","                return\n","\n","            # Draw rectangles\n","            result_img = draw_faces(img_with_faces, faces, rect_color)\n","            if result_img is None:\n","                st.error(\"No faces detected in the image.\")\n","                return\n","\n","            # Convert back to RGB for display\n","            result_img_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n","            result_pil = Image.fromarray(result_img_rgb)\n","\n","            # Display result\n","            st.image(result_pil, caption=f\"Detected {len(faces)} faces\", use_column_width=True)\n","\n","            # Save image option\n","            if st.button(\"Save Image\"):\n","                output_path = \"detected_faces_output.jpg\"\n","                result_pil.save(output_path, format=\"JPEG\")\n","                st.success(f\"Image saved as {output_path}\")\n","                # Provide download link\n","                with open(output_path, \"rb\") as file:\n","                    st.download_button(\n","                        label=\"Download Image\",\n","                        data=file,\n","                        file_name=\"detected_faces_output.jpg\",\n","                        mime=\"image/jpeg\"\n","                    )\n","\n","        except Exception as e:\n","            st.error(f\"Error processing image: {e}\")\n","\n","    else:\n","        st.info(\"Please upload an image to start face detection.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d1a0a1c","executionInfo":{"status":"ok","timestamp":1755255385333,"user_tz":-180,"elapsed":19,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"72d479f9-7958-4731-a3ee-55ebb815f2ac"},"source":["%%writefile app.py\n","import streamlit as st\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import os\n","\n","def detect_faces(image, scale_factor, min_neighbors):\n","    \"\"\"Detect faces in the image using Viola-Jones algorithm.\"\"\"\n","    # Convert PIL image to OpenCV format\n","    img_array = np.array(image)\n","    if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n","        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n","    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n","\n","    # Load Haar cascade\n","    # Assuming the cascade file is in the same directory as the app.py file\n","    cascade_path = \"haarcascade_frontalface_default.xml\"\n","    if not os.path.exists(cascade_path):\n","        st.error(\"Error: Haar cascade file 'haarcascade_frontalface_default.xml' not found.\")\n","        st.info(\"Please make sure 'haarcascade_frontalface_default.xml' is in the same directory as app.py\")\n","        return None, []\n","\n","    face_cascade = cv2.CascadeClassifier(cascade_path)\n","    if face_cascade.empty():\n","        st.error(\"Error: Failed to load Haar cascade classifier.\")\n","        return None, []\n","\n","    # Detect faces\n","    faces = face_cascade.detectMultiScale(\n","        gray,\n","        scaleFactor=scale_factor,\n","        minNeighbors=min_neighbors,\n","        minSize=(30, 30)\n","    )\n","\n","    return img_array, faces\n","\n","def draw_faces(image, faces, color_hex):\n","    \"\"\"Draw rectangles around detected faces with the chosen color.\"\"\"\n","    if image is None:\n","        return None\n","\n","    # Convert hex color to BGR\n","    color_rgb = tuple(int(color_hex.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n","    color_bgr = (color_rgb[2], color_rgb[1], color_rgb[0])  # Reverse to BGR\n","\n","    img_copy = image.copy()\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(img_copy, (x, y), (x + w, y + h), color_bgr, 2)\n","\n","    return img_copy\n","\n","def main():\n","    \"\"\"Streamlit app for face detection.\"\"\"\n","    st.title(\"Face Detection with Viola-Jones Algorithm\")\n","\n","    # Instructions\n","    st.markdown(\"\"\"\n","    **Instructions:**\n","    1. Upload an image (JPG, PNG) containing faces.\n","    2. Adjust the **Scale Factor** and **Min Neighbors** sliders to fine-tune face detection.\n","    3. Choose a color for the face detection rectangles using the color picker.\n","    4. View the image with detected faces.\n","    5. Click the **Save Image** button to download the result.\n","    \"\"\")\n","\n","    # File uploader\n","    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n","\n","    # Parameters\n","    scale_factor = st.slider(\n","        \"Scale Factor (controls detection sensitivity)\",\n","        min_value=1.1,\n","        max_value=2.0,\n","        value=1.3,\n","        step=0.1\n","    )\n","    min_neighbors = st.slider(\n","        \"Min Neighbors (controls detection strictness)\",\n","        min_value=3,\n","        max_value=10,\n","        value=5,\n","        step=1\n","    )\n","    rect_color = st.color_picker(\"Choose rectangle color\", \"#FF0000\")\n","\n","    if uploaded_file is not None:\n","        try:\n","            # Load image\n","            image = Image.open(uploaded_file)\n","            if image.mode != 'RGB':\n","                image = image.convert('RGB')\n","\n","            # Detect faces\n","            img_with_faces, faces = detect_faces(image, scale_factor, min_neighbors)\n","\n","            if img_with_faces is None:\n","                # Error message is shown in detect_faces\n","                return\n","\n","            # Draw rectangles\n","            result_img = draw_faces(img_with_faces, faces, rect_color)\n","            if result_img is None:\n","                st.error(\"No faces detected in the image.\")\n","                return\n","\n","            # Convert back to RGB for display\n","            result_img_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n","            result_pil = Image.fromarray(result_img_rgb)\n","\n","            # Display result\n","            st.image(result_pil, caption=f\"Detected {len(faces)} faces\", use_column_width=True)\n","\n","            # Save image option\n","            # Convert PIL Image to bytes\n","            from io import BytesIO\n","            buf = BytesIO()\n","            result_pil.save(buf, format=\"PNG\")\n","            byte_im = buf.getvalue()\n","\n","            st.download_button(\n","                label=\"Download Image with Faces\",\n","                data=byte_im,\n","                file_name=\"detected_faces_output.png\",\n","                mime=\"image/png\"\n","            )\n","\n","\n","        except Exception as e:\n","            st.error(f\"Error processing image: {e}\")\n","\n","    else:\n","        st.info(\"Please upload an image to start face detection.\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49efab45","executionInfo":{"status":"ok","timestamp":1755255385505,"user_tz":-180,"elapsed":166,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"5b3fa919-1da7-4c7d-f95e-de7fc29ff653"},"source":["# Download the Haar cascade file\n","!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-08-15 10:56:24--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 930127 (908K) [text/plain]\n","Saving to: ‘haarcascade_frontalface_default.xml’\n","\n","haarcascade_frontal 100%[===================>] 908.33K  --.-KB/s    in 0.06s   \n","\n","2025-08-15 10:56:24 (16.0 MB/s) - ‘haarcascade_frontalface_default.xml’ saved [930127/930127]\n","\n"]}]}]}