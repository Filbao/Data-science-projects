{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMxx9z4vhF3WHpii/lGlxS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["***Instructions***"],"metadata":{"id":"qTkp74DzvaHR"}},{"cell_type":"markdown","source":["Choose a topic: Choose a topic that you are interested in and find a text file related to that topic. You can use websites such as Project Gutenberg to find free text files.\n","Preprocess the data: Modify the preprocess() function in the code provided to preprocess the data in your text file. You may want to modify the stop words list or add additional preprocessing steps to better suit your needs.\n","Define the similarity function: Modify the get_most_relevant_sentence() function to compute the similarity between the user's query and each sentence in your text file. You may want to modify the similarity metric or add additional features to improve the performance of your chatbot.\n","Define the chatbot function: Modify the chatbot() function to return an appropriate response based on the most relevant sentence in your text file.\n","Create a Streamlit app: Use the main() function in the code provided as a template to create a web-based chatbot interface. Prompt the user for a question, call the chatbot() function to get the response, and display it on the screen."],"metadata":{"id":"V6AWujKdvftT"}},{"cell_type":"code","source":["import re\n","import nltk\n","import string\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import streamlit as st\n","\n","# Download NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab') # Added to fix the LookupError\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","# Custom stop words list (remove conversation-relevant terms)\n","default_stopwords = set(stopwords.words('english'))\n","custom_stopwords = default_stopwords - {'school', 'weather', 'rain', 'beach', 'movie', 'health', 'cold', 'pain'}\n","\n","def preprocess(text):\n","    \"\"\"Preprocess the dialogs text.\"\"\"\n","    # Convert to lowercase\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    # Split into lines and treat each line as a sentence\n","    lines = text.strip().split('\\n')\n","    sentences = []\n","    for line in lines:\n","        # Split line into question and response (tab-separated)\n","        parts = line.split('\\t')\n","        # Include both question and response as separate sentences\n","        sentences.extend([part.strip() for part in parts if part.strip()])\n","\n","    # Clean sentences: remove extra whitespace, short sentences (< 3 words)\n","    cleaned_sentences = [s for s in sentences if len(word_tokenize(s)) >= 3]\n","\n","    return cleaned_sentences\n","\n","def get_most_relevant_sentence(query, sentences):\n","    \"\"\"Find the most relevant sentence to the query using TF-IDF and cosine similarity.\"\"\"\n","    # Preprocess query\n","    query = query.lower().translate(str.maketrans('', '', string.punctuation))\n","\n","    # Combine query and sentences for TF-IDF\n","    documents = [query] + sentences\n","\n","    # Create TF-IDF vectorizer with bigrams for better phrase matching\n","    vectorizer = TfidfVectorizer(stop_words=list(custom_stopwords), ngram_range=(1, 2))\n","    tfidf_matrix = vectorizer.fit_transform(documents)\n","\n","    # Compute cosine similarity\n","    similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n","\n","    # Normalize by sentence length to favor concise responses\n","    lengths = [len(word_tokenize(s)) for s in sentences]\n","    normalized_similarities = [sim / (length ** 0.5) if length > 0 else 0 for sim, length in zip(similarities, lengths)]\n","\n","    # Find the index of the highest similarity\n","    if len(normalized_similarities) == 0:\n","        return None, 0.0\n","    best_idx = np.argmax(normalized_similarities)\n","    best_score = normalized_similarities[best_idx]\n","\n","    return sentences[best_idx], best_score\n","\n","def chatbot(query, sentences):\n","    \"\"\"Return a response based on the most relevant sentence.\"\"\"\n","    relevant_sentence, score = get_most_relevant_sentence(query, sentences)\n","\n","    if score > 0.05:  # Lower threshold for conversational text\n","        return relevant_sentence.capitalize() + '.'\n","    else:\n","        return \"Sorry, I couldn't find a relevant response in the dialogs. Try asking about school, weather, or plans!\"\n","\n","def chatbot():\n","    \"\"\"Interactive chatbot function to respond to user queries.\"\"\"\n","    # Load and preprocess the dialogs file\n","    try:\n","        with open('/content/dialogs.txt', 'r', encoding='utf-8') as file:\n","            text = file.read()\n","    except FileNotFoundError:\n","        print(\"Error: 'dialogs.txt' not found in the current directory.\")\n","        return\n","\n","    sentences = preprocess(text)\n","    print(f\"Loaded {len(sentences)} sentences from dialogs.txt\")\n","    print(\"Chatbot ready! Type your question (or 'quit' to exit):\")\n","\n","    while True:\n","        # Get user input\n","        query = input(\"> \")\n","        if query.lower() in ['quit', 'exit']:\n","            print(\"Goodbye!\")\n","            break\n","        if not query.strip():\n","            print(\"Please enter a valid question.\")\n","            continue\n","\n","        # Find and print the response\n","        response, score = get_most_relevant_sentence(query, sentences)\n","        if score > 0.05:\n","            print(response.capitalize() + '.')\n","        else:\n","            print(\"Sorry, I couldn't find a relevant response. Try asking about school, weather, health, or plans!\")\n","\n","\n","def main():\n","    \"\"\"Streamlit app for the chatbot.\"\"\"\n","    st.title(\"Conversational Chatbot\")\n","    st.write(\"Ask a question about school, weather, health, or social plans, and I'll respond based on a conversational dialog dataset.\")\n","\n","    # Load and preprocess the dialogs file\n","    with open('dialogs.txt', 'r', encoding='utf-8') as file:\n","        text = file.read()\n","    sentences = preprocess(text)\n","\n","    # User input\n","    query = st.text_input(\"Enter your question:\", \"\")\n","\n","    if query:\n","        response = chatbot(query, sentences)\n","        st.write(\"**Response:**\")\n","        st.write(response)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9CedJ66-htp","executionInfo":{"status":"ok","timestamp":1755166879314,"user_tz":-180,"elapsed":441,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"c460d3dd-65af-4f7d-a168-2c5404fa7f33"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","2025-08-14 10:21:18.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.525 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.983 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.985 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-14 10:21:18.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c69c3e5b","executionInfo":{"status":"ok","timestamp":1755166879346,"user_tz":-180,"elapsed":25,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"ca03957d-1340-4ba7-cd66-96a1b142da7f"},"source":["%%writefile chatbot_app.py\n","import re\n","import nltk\n","import string\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import streamlit as st\n","\n","# Download NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab') # Added to fix the LookupError\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","# Custom stop words list (remove conversation-relevant terms)\n","default_stopwords = set(stopwords.words('english'))\n","custom_stopwords = default_stopwords - {'school', 'weather', 'rain', 'beach', 'movie', 'health', 'cold', 'pain'}\n","\n","def preprocess(text):\n","    \"\"\"Preprocess the dialogs text.\"\"\"\n","    # Convert to lowercase\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    # Split into lines and treat each line as a sentence\n","    lines = text.strip().split('\\n')\n","    sentences = []\n","    for line in lines:\n","        # Split line into question and response (tab-separated)\n","        parts = line.split('\\t')\n","        # Include both question and response as separate sentences\n","        sentences.extend([part.strip() for part in parts if part.strip()])\n","\n","    # Clean sentences: remove extra whitespace, short sentences (< 3 words)\n","    cleaned_sentences = [s for s in sentences if len(word_tokenize(s)) >= 3]\n","\n","    return cleaned_sentences\n","\n","def get_most_relevant_sentence(query, sentences):\n","    \"\"\"Find the most relevant sentence to the query using TF-IDF and cosine similarity.\"\"\"\n","    # Preprocess query\n","    query = query.lower().translate(str.maketrans('', '', string.punctuation))\n","\n","    # Combine query and sentences for TF-IDF\n","    documents = [query] + sentences\n","\n","    # Create TF-IDF vectorizer with bigrams for better phrase matching\n","    vectorizer = TfidfVectorizer(stop_words=list(custom_stopwords), ngram_range=(1, 2))\n","    tfidf_matrix = vectorizer.fit_transform(documents)\n","\n","    # Compute cosine similarity\n","    similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n","\n","    # Normalize by sentence length to favor concise responses\n","    lengths = [len(word_tokenize(s)) for s in sentences]\n","    normalized_similarities = [sim / (length ** 0.5) if length > 0 else 0 for sim, length in zip(similarities, lengths)]\n","\n","    # Find the index of the highest similarity\n","    if len(normalized_similarities) == 0:\n","        return None, 0.0\n","    best_idx = np.argmax(normalized_similarities)\n","    best_score = normalized_similarities[best_idx]\n","\n","    return sentences[best_idx], best_score\n","\n","def chatbot(query, sentences):\n","    \"\"\"Return a response based on the most relevant sentence.\"\"\"\n","    relevant_sentence, score = get_most_relevant_sentence(query, sentences)\n","\n","    if score > 0.05:  # Lower threshold for conversational text\n","        return relevant_sentence.capitalize() + '.'\n","    else:\n","        return \"Sorry, I couldn't find a relevant response in the dialogs. Try asking about school, weather, or plans!\"\n","\n","def main():\n","    \"\"\"Streamlit app for the chatbot.\"\"\"\n","    st.title(\"Conversational Chatbot\")\n","    st.write(\"Ask a question about school, weather, health, or social plans, and I'll respond based on a conversational dialog dataset.\")\n","\n","    # Load and preprocess the dialogs file\n","    try:\n","        with open('/content/dialogs.txt', 'r', encoding='utf-8') as file:\n","            text = file.read()\n","    except FileNotFoundError:\n","        st.error(\"Error: '/content/dialogs.txt' not found in the current directory.\")\n","        return\n","\n","    sentences = preprocess(text)\n","\n","    # User input\n","    query = st.text_input(\"Enter your question:\", \"\")\n","\n","    if query:\n","        response = chatbot(query, sentences)\n","        st.write(\"**Response:**\")\n","        st.write(response)\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting chatbot_app.py\n"]}]},{"cell_type":"markdown","metadata":{"id":"c9bbf2c4"},"source":["Now that the code is saved as `chatbot_app.py`, you can run the Streamlit app using the following command in a **shell cell** (a cell starting with `!`) or a new **code cell** starting with `!`:"]}]}