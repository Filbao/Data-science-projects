{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+l4XyVR1C/t3XvJPd7qUl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1.First, import the necessary packages in your code. This includes nltk, streamlit, and speech_recognition.\n"],"metadata":{"id":"ITvBoMYX-JoH"}},{"cell_type":"code","source":["import nltk\n","import random\n","import streamlit as st\n","import speech_recognition as sr\n","\n","# Download punkt tokenizer (first time only)\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8u8-s1FPA9_m","executionInfo":{"status":"ok","timestamp":1755501033310,"user_tz":-180,"elapsed":1390,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"026803e5-6fee-4afd-d14f-3d9bfedb3e27"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["2.Load the text file and preprocess the data using the chatbot algorithm.\n"],"metadata":{"id":"sIVnv27LClcE"}},{"cell_type":"code","source":["def load_dialogs(file_path):\n","    pairs = []\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            parts = line.strip().split(\"\\t\")\n","            if len(parts) == 2:\n","                pairs.append((parts[0].lower(), parts[1].lower()))\n","    return pairs\n","\n","dialogs = load_dialogs(\"dialogs.txt\")"],"metadata":{"id":"sgMp1yymCm2G","executionInfo":{"status":"ok","timestamp":1755501945547,"user_tz":-180,"elapsed":48,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["3.Define a function to transcribe speech into text using the speech recognition algorithm.\n"],"metadata":{"id":"w2wednWmEWia"}},{"cell_type":"code","source":["def chatbot_response(user_input):\n","    user_input = user_input.lower()\n","    for q, a in dialogs:\n","        if q in user_input:\n","            return a\n","    return random.choice([\n","        \"That's interesting. Tell me more!\",\n","        \"I see. Can you explain further?\",\n","        \"Hmm, I'm not sure I understand. Can you rephrase?\"\n","    ])"],"metadata":{"id":"wVZPTiV4EYtt","executionInfo":{"status":"ok","timestamp":1755501966199,"user_tz":-180,"elapsed":22,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["4.Modify the chatbot function to take both text and speech input from the user. If the user provides text input, the chatbot should function as before. If the user provides speech input, the speech recognition algorithm should transcribe the speech into text, which is then passed to the chatbot.\n"],"metadata":{"id":"mHkkatcLEnnx"}},{"cell_type":"code","source":["def transcribe_speech():\n","    recognizer = sr.Recognizer()\n","    with sr.Microphone() as source:\n","        st.info(\"üé§ Listening... please speak now\")\n","        try:\n","            audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)\n","            text = recognizer.recognize_google(audio)\n","            return text\n","        except sr.WaitTimeoutError:\n","            return \"Sorry, I didn‚Äôt hear anything.\"\n","        except sr.UnknownValueError:\n","            return \"Sorry, I couldn‚Äôt understand your speech.\"\n","        except sr.RequestError:\n","            return \"Sorry, there was an issue with the recognition service.\""],"metadata":{"id":"KyahYmrNFTd7","executionInfo":{"status":"ok","timestamp":1755502205212,"user_tz":-180,"elapsed":39,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["5.Create a Streamlit app that allows the user to provide either text or speech input to the chatbot. If the user provides text input, the chatbot should function as before. If the user provides speech input, the speech recognition algorithm should transcribe the speech into text, which is then passed to the chatbot. The chatbot's response should be displayed to the user.\n"],"metadata":{"id":"FeIsp-9WFgNm"}},{"cell_type":"code","source":["st.title(\"ü§ñ Chatbot with Text & Speech Input\")\n","\n","# Let user choose input type\n","input_mode = st.radio(\"Choose input method:\", [\"Text\", \"Speech\"])\n","\n","user_input = \"\"\n","\n","if input_mode == \"Text\":\n","    user_input = st.text_input(\"Type your message here:\")\n","\n","elif input_mode == \"Speech\":\n","    if st.button(\"üéôÔ∏è Speak\"):\n","        user_input = transcribe_speech()\n","        st.write(f\"üìù Transcribed: {user_input}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"411iJKxFFhxh","executionInfo":{"status":"ok","timestamp":1755502256702,"user_tz":-180,"elapsed":236,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"871b5461-c332-4d58-d191-270a40f774cc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-08-18 07:30:56.281 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.392 \n","  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n","  command:\n","\n","    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n","2025-08-18 07:30:56.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.396 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.399 Session state does not function when running a script without `streamlit run`\n","2025-08-18 07:30:56.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.408 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.411 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.412 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.413 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-08-18 07:30:56.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"]}]},{"cell_type":"markdown","source":["6.Test the chatbot with both text and speech input to ensure that it functions correctly.\n"],"metadata":{"id":"kgHrEzQHFtDk"}},{"cell_type":"code","source":["if user_input:\n","    response = chatbot_response(user_input)\n","    st.markdown(f\"**ü§ñ Bot:** {response}\")"],"metadata":{"id":"wusOVzSQFulI","executionInfo":{"status":"ok","timestamp":1755502287901,"user_tz":-180,"elapsed":21,"user":{"displayName":"Filbao","userId":"06534393836955986277"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acdf03e1","executionInfo":{"status":"ok","timestamp":1755503208389,"user_tz":-180,"elapsed":78,"user":{"displayName":"Filbao","userId":"06534393836955986277"}},"outputId":"152df394-b5a4-48f1-d28f-6ff12d7435f7"},"source":["%%writefile app.py\n","import nltk\n","import random\n","import streamlit as st\n","import speech_recognition as sr\n","\n","# Download punkt tokenizer\n","try:\n","    nltk.data.find('tokenizers/punkt')\n","except nltk.downloader.DownloadError:\n","    nltk.download('punkt')\n","\n","\n","def load_dialogs(file_path):\n","    pairs = []\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            parts = line.strip().split(\"\\t\")\n","            if len(parts) == 2:\n","                pairs.append((parts[0].lower(), parts[1].lower()))\n","    return pairs\n","\n","# Assuming 'dialogs.txt' is in the same directory as app.py\n","try:\n","    dialogs = load_dialogs(\"dialogs.txt\")\n","except FileNotFoundError:\n","    st.error(\"dialogs.txt not found. Please make sure it's in the same directory as app.py\")\n","    st.stop()\n","\n","\n","def chatbot_response(user_input):\n","    user_input = user_input.lower()\n","    for q, a in dialogs:\n","        if q in user_input:\n","            return a\n","    return random.choice([\n","        \"That's interesting. Tell me more!\",\n","        \"I see. Can you explain further?\",\n","        \"Hmm, I'm not sure I understand. Can you rephrase?\"\n","    ])\n","\n","\n","def transcribe_speech():\n","    recognizer = sr.Recognizer()\n","    with sr.Microphone() as source:\n","        st.info(\"üé§ Listening... please speak now\")\n","        try:\n","            audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)\n","            text = recognizer.recognize_google(audio)\n","            return text\n","        except sr.WaitTimeoutError:\n","            st.warning(\"Sorry, I didn‚Äôt hear anything.\")\n","            return \"\"\n","        except sr.UnknownValueError:\n","            st.warning(\"Sorry, I couldn‚Äôt understand your speech.\")\n","            return \"\"\n","        except sr.RequestError:\n","            st.error(\"Sorry, there was an issue with the recognition service.\")\n","            return \"\"\n","\n","\n","st.title(\"ü§ñ Chatbot with Text & Speech Input\")\n","\n","# Let user choose input type\n","input_mode = st.radio(\"Choose input method:\", [\"Text\", \"Speech\"])\n","\n","user_input = \"\"\n","\n","if input_mode == \"Text\":\n","    user_input = st.text_input(\"Type your message here:\")\n","\n","elif input_mode == \"Speech\":\n","    if st.button(\"üéôÔ∏è Speak\"):\n","        user_input = transcribe_speech()\n","        if user_input:\n","            st.write(f\"üìù Transcribed: {user_input}\")\n","\n","if user_input:\n","    response = chatbot_response(user_input)\n","    st.markdown(f\"**ü§ñ Bot:** {response}\")"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]}]}